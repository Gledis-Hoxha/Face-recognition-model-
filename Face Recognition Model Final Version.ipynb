{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from datetime import datetime, timedelta\n",
    "from deepface import DeepFace\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='face_recognition.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define the path to the ONNX model files\n",
    "face_detection_model_path = \"face_detection_yunet_2023mar.onnx\"\n",
    "face_recognition_model_path = \"face_recognition_sface_2021dec.onnx\"\n",
    "\n",
    "# Check if the ONNX model files exist\n",
    "if not os.path.exists(face_detection_model_path):\n",
    "    logging.error(f\"Face detection model file not found: {face_detection_model_path}\")\n",
    "    raise FileNotFoundError(f\"Face detection model file not found: {face_detection_model_path}\")\n",
    "\n",
    "if not os.path.exists(face_recognition_model_path):\n",
    "    logging.error(f\"Face recognition model file not found: {face_recognition_model_path}\")\n",
    "    raise FileNotFoundError(f\"Face recognition model file not found: {face_recognition_model_path}\")\n",
    "\n",
    "# Load the face detection and recognition models\n",
    "detector = cv.FaceDetectorYN.create(\n",
    "    face_detection_model_path,\n",
    "    \"\",\n",
    "    (320, 320),\n",
    "    0.7,\n",
    "    0.3,\n",
    "    5000,\n",
    "    backend_id=3\n",
    ")\n",
    "recognizer = cv.FaceRecognizerSF.create(\n",
    "    face_recognition_model_path, \"\", backend_id=3)\n",
    "\n",
    "# Set the cosine similarity threshold for face recognition\n",
    "cosine_similarity_threshold = 0.35\n",
    "\n",
    "# Define the path to the images directory\n",
    "path_to_images = \"Faces\"\n",
    "\n",
    "# Load the embeddings from the CSV file if it exists and is not empty, otherwise create an empty DataFrame\n",
    "embeddings_file = \"embeddings_df.csv\"\n",
    "if os.path.exists(embeddings_file) and os.path.getsize(embeddings_file) > 0:\n",
    "    embeddings_df = pd.read_csv(embeddings_file)\n",
    "    embeddings_df['Embedding'] = embeddings_df['Embedding'].apply(lambda x: np.array([float(t) for t in x.replace('[', '').replace(']', '').split()]))\n",
    "else:\n",
    "    embeddings_df = pd.DataFrame(columns=['Name', 'Embedding'])\n",
    "\n",
    "# Remove any rows with empty or incorrectly formatted embeddings\n",
    "embeddings_df = embeddings_df[embeddings_df['Embedding'].apply(lambda x: len(x) == 128)]\n",
    "\n",
    "# Set up Google Sheets credentials\n",
    "scope = ['https://www.googleapis.com/auth/drive']\n",
    "json_keyfile_path = r'face-recognition-credentials.json'  # Update with your file path\n",
    "\n",
    "# Check if the JSON keyfile exists\n",
    "if not os.path.exists(json_keyfile_path):\n",
    "    logging.error(f\"Google Sheets API credentials file not found: {json_keyfile_path}\")\n",
    "    raise FileNotFoundError(f\"Google Sheets API credentials file not found: {json_keyfile_path}\")\n",
    "\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Specify the Google Sheets document by its URL\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1FvV0U8OOtMRFItP2XbrlHPiFaPoa-xwDTRF4AMVbVGI/edit?gid=0#gid=0\"\n",
    "\n",
    "# Open the Google Sheets document\n",
    "doc = client.open_by_url(sheet_url)\n",
    "\n",
    "# Print out the names of all worksheets\n",
    "worksheets = doc.worksheets()\n",
    "print(\"Available worksheets:\")\n",
    "for worksheet in worksheets:\n",
    "    print(worksheet.title)\n",
    "\n",
    "# Try to get the worksheet named \"Face\"\n",
    "try:\n",
    "    sheet = doc.worksheet(\"Face\")\n",
    "    print('Worksheet \"Face\" found and accessed successfully.')\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    print('Worksheet \"Face\" not found. Creating a new one.')\n",
    "    sheet = doc.add_worksheet(title=\"Face\", rows=\"1000\", cols=\"20\")\n",
    "    sheet.append_row([\"Identity\", \"Timestamp\", \"Emotion\"])\n",
    "\n",
    "# Function to delete processed images from the \"Faces\" folder\n",
    "def delete_processed_images():\n",
    "    for filename in os.listdir(path_to_images):\n",
    "        image_name = filename[:-4]  # Remove the file extension\n",
    "        if image_name in embeddings_df['Name'].values:\n",
    "            os.remove(os.path.join(path_to_images, filename))\n",
    "            print(f\"Deleted processed image: {filename}\")\n",
    "\n",
    "# Function to generate embeddings for known faces\n",
    "def generate_embeddings():\n",
    "    global embeddings_df\n",
    "    for filename in os.listdir(path_to_images):\n",
    "        if filename.startswith(\"Unknown_\"):\n",
    "            continue  # Skip processing unknown face images\n",
    "        img_path = os.path.join(path_to_images, filename)\n",
    "        img = cv.imread(img_path)\n",
    "        if img is not None:\n",
    "            detector.setInputSize([img.shape[1], img.shape[0]])\n",
    "            face = detector.detect(img)\n",
    "            if face[1] is not None:\n",
    "                coords = face[1][0].astype(np.int32)\n",
    "                if (coords[2] >= 40) and (coords[3] >= 40):\n",
    "                    face_align = recognizer.alignCrop(img, face[1][0])\n",
    "                    face_feature = recognizer.feature(face_align)\n",
    "                    if face_feature.size == 128:  # Check for correct size\n",
    "                        x = {\"Name\": filename[:-4], \"Embedding\": face_feature}\n",
    "                        if filename[:-4] not in embeddings_df['Name'].values:\n",
    "                            embeddings_df = pd.concat(\n",
    "                                [\n",
    "                                    embeddings_df,\n",
    "                                    pd.DataFrame.from_dict([x], orient='columns')\n",
    "                                ],\n",
    "                                ignore_index=True)\n",
    "                    else:\n",
    "                        logging.warning(f\"Incorrect feature size for {filename}\")\n",
    "        else:\n",
    "            print(f\"Failed to read image: {img_path}\")\n",
    "\n",
    "# Save the updated embeddings to the CSV file\n",
    "def save_embeddings():\n",
    "    embeddings_df.to_csv(embeddings_file, index=False)\n",
    "\n",
    "# Function to visualize the detected faces, identities, and emotions\n",
    "def visualize(input, faces, identities=[], emotions=[], thickness=2):\n",
    "    if faces[1] is not None:\n",
    "        for idx, face in enumerate(faces[1]):\n",
    "            coords = face[:-1].astype(np.int32)\n",
    "            cv.rectangle(input, (coords[0], coords[1]), (coords[0]+coords[2], coords[1]+coords[3]), (0, 255, 0), thickness)\n",
    "            if identities:\n",
    "                cv.putText(input, identities[idx], (coords[0], coords[1]-10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            if emotions:\n",
    "                cv.putText(input, emotions[idx], (coords[0], coords[1]+coords[3]+20), cv.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "# Open the video capture\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "new_resolution = 1\n",
    "\n",
    "# Dictionary to store the last detection timestamp and image count for each identity\n",
    "last_detection_time = {}\n",
    "image_count = {}\n",
    "\n",
    "# Dictionary to track detection statistics\n",
    "detection_stats = {\n",
    "    \"faces\": {},\n",
    "    \"persons\": {},\n",
    "    \"moods\": {}\n",
    "}\n",
    "\n",
    "# Function to determine if an image is blurry\n",
    "def is_blurry(image, threshold=100.0):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    laplacian_var = cv.Laplacian(gray, cv.CV_64F).var()\n",
    "    return laplacian_var < threshold\n",
    "\n",
    "# Function to update detection statistics\n",
    "def update_detection_stats(identity, emotion, timestamp):\n",
    "    if identity not in detection_stats[\"faces\"]:\n",
    "        detection_stats[\"faces\"][identity] = 0\n",
    "    detection_stats[\"faces\"][identity] += 1\n",
    "\n",
    "    if emotion not in detection_stats[\"moods\"]:\n",
    "        detection_stats[\"moods\"][emotion] = 0\n",
    "    detection_stats[\"moods\"][emotion] += 1\n",
    "\n",
    "    if timestamp not in detection_stats[\"persons\"]:\n",
    "        detection_stats[\"persons\"][timestamp] = {\"identity\": identity, \"count\": 0}\n",
    "    detection_stats[\"persons\"][timestamp][\"count\"] += 1\n",
    "\n",
    "# Function to get the most detected face, person, and mood\n",
    "def get_most_detected():\n",
    "    most_detected_face = max(detection_stats[\"faces\"], key=detection_stats[\"faces\"].get)\n",
    "    most_detected_mood = max(detection_stats[\"moods\"], key=detection_stats[\"moods\"].get)\n",
    "    most_detected_time = max(detection_stats[\"persons\"], key=lambda x: detection_stats[\"persons\"][x][\"count\"])\n",
    "    most_detected_person = detection_stats[\"persons\"][most_detected_time][\"identity\"]\n",
    "    return most_detected_face, most_detected_mood, most_detected_person, most_detected_time\n",
    "\n",
    "# Main loop for face recognition and emotion detection\n",
    "def main_loop():\n",
    "    global embeddings_df\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            pic_width = int(frame.shape[1] * new_resolution)\n",
    "            pic_height = int(frame.shape[0] * new_resolution)\n",
    "            new_dimension = (pic_width, pic_height)\n",
    "\n",
    "            frame = cv.resize(frame, new_dimension, interpolation=cv.INTER_AREA)\n",
    "\n",
    "            detector.setInputSize([frame.shape[1], frame.shape[0]])\n",
    "            faces = detector.detect(frame)\n",
    "\n",
    "            identities = []\n",
    "            emotions = []\n",
    "            if faces[1] is not None:\n",
    "                for i in range(len(faces[1])):\n",
    "                    coords = faces[1][i].astype(np.int32)\n",
    "                    if faces[1][i][-1] >= 0.7:\n",
    "                        face1_align = recognizer.alignCrop(frame, faces[1][i])\n",
    "                        if is_blurry(face1_align):\n",
    "                            continue  # Skip processing blurry images\n",
    "                        face1_feature = recognizer.feature(face1_align)\n",
    "                        identity = \"\"\n",
    "                        if face1_feature.size == 128:  # Ensure correct feature size\n",
    "                            embeddings_df['cosine'] = embeddings_df.Embedding.apply(\n",
    "                                lambda x: int(recognizer.match(face1_feature, np.reshape(x, face1_feature.shape).astype(np.float32), cv.FaceRecognizerSF_FR_COSINE) > cosine_similarity_threshold))\n",
    "                            a = embeddings_df[embeddings_df.cosine == 1]\n",
    "                            if len(a):\n",
    "                                identity = a.Name.iloc[0].capitalize()\n",
    "                            else:\n",
    "                                # Save the unknown face image in the \"Faces\" folder with limitation\n",
    "                                timestamp = datetime.now()\n",
    "                                if \"Unknown\" not in image_count:\n",
    "                                    image_count[\"Unknown\"] = 0\n",
    "                                    last_detection_time[\"Unknown\"] = timestamp\n",
    "                                if (timestamp - last_detection_time[\"Unknown\"]) < timedelta(minutes=1):\n",
    "                                    if image_count[\"Unknown\"] < 3:\n",
    "                                        unknown_filename = f\"Unknown_{timestamp.strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                                        unknown_path = os.path.join(path_to_images, unknown_filename)\n",
    "                                        cv.imwrite(unknown_path, face1_align)\n",
    "                                        image_count[\"Unknown\"] += 1\n",
    "                                else:\n",
    "                                    image_count[\"Unknown\"] = 1\n",
    "                                    last_detection_time[\"Unknown\"] = timestamp\n",
    "                                    unknown_filename = f\"Unknown_{timestamp.strftime('%Y%m%d_%H%M%S')}.jpg\"\n",
    "                                    unknown_path = os.path.join(path_to_images, unknown_filename)\n",
    "                                    cv.imwrite(unknown_path, face1_align)\n",
    "                                identity = \"Unknown\"\n",
    "                        else:\n",
    "                            logging.warning(\"Empty or incorrect feature vector for detected face.\")\n",
    "                            identity = \"Unknown\"\n",
    "\n",
    "                        identities.append(identity)\n",
    "\n",
    "                        # Detect emotion using DeepFace\n",
    "                        try:\n",
    "                            emotion_analysis = DeepFace.analyze(face1_align, actions=['emotion'], enforce_detection=False)\n",
    "                            if isinstance(emotion_analysis, list):\n",
    "                                if len(emotion_analysis) > 0 and 'dominant_emotion' in emotion_analysis[0]:\n",
    "                                    emotion = emotion_analysis[0]['dominant_emotion']\n",
    "                                else:\n",
    "                                    emotion = \"Unknown\"\n",
    "                            elif isinstance(emotion_analysis, dict) and 'dominant_emotion' in emotion_analysis:\n",
    "                                emotion = emotion_analysis['dominant_emotion']\n",
    "                            else:\n",
    "                                emotion = \"Unknown\"\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Error in emotion analysis: {e}\")\n",
    "                            emotion = \"Unknown\"\n",
    "\n",
    "                        emotions.append(emotion)\n",
    "\n",
    "                        # Update detection statistics\n",
    "                        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                        update_detection_stats(identity, emotion, timestamp)\n",
    "\n",
    "                        # Store the detection details in Google Sheets if the time difference is at least 5 seconds\n",
    "                        current_time = datetime.now()\n",
    "                        if identity not in last_detection_time or (current_time - last_detection_time[identity]).total_seconds() >= 5:\n",
    "                            last_detection_time[identity] = current_time\n",
    "                            row = [identity, timestamp, emotion]\n",
    "                            try:\n",
    "                                logging.info(f\"Appending row to Google Sheets: {row}\")\n",
    "                                sheet.append_row(row)\n",
    "                                logging.info(\"Row appended successfully.\")\n",
    "                            except Exception as e:\n",
    "                                logging.error(f\"Failed to append row to Google Sheets: {e}\")\n",
    "\n",
    "            visualize(frame, faces, identities, emotions)\n",
    "\n",
    "            cv.imshow('frame', frame)\n",
    "            if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "    # Get and log the most detected face, person, and mood\n",
    "    most_detected_face, most_detected_mood, most_detected_person, most_detected_time = get_most_detected()\n",
    "    logging.info(f\"Most detected face: {most_detected_face}\")\n",
    "    logging.info(f\"Most detected mood: {most_detected_mood}\")\n",
    "    logging.info(f\"Most detected person: {most_detected_person} at {most_detected_time}\")\n",
    "\n",
    "    # Print the results to the console\n",
    "    print(f\"Most detected face: {most_detected_face}\")\n",
    "    print(f\"Most detected mood: {most_detected_mood}\")\n",
    "    print(f\"Most detected person: {most_detected_person} at {most_detected_time}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_embeddings()\n",
    "    save_embeddings()\n",
    "    delete_processed_images()\n",
    "    main_loop()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up Google Sheets credentials\n",
    "scope = ['https://www.googleapis.com/auth/drive']\n",
    "json_keyfile_path = r'face-recognition-credentials.json'  # Update with your file path\n",
    "\n",
    "# Check if the JSON keyfile exists\n",
    "if not os.path.exists(json_keyfile_path):\n",
    "    raise FileNotFoundError(f\"Google Sheets API credentials file not found: {json_keyfile_path}\")\n",
    "\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(json_keyfile_path, scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "# Specify the Google Sheets document by its URL\n",
    "sheet_url = \"https://docs.google.com/spreadsheets/d/1FvV0U8OOtMRFItP2XbrlHPiFaPoa-xwDTRF4AMVbVGI/edit?gid=0#gid=0\"\n",
    "\n",
    "# Open the Google Sheets document\n",
    "doc = client.open_by_url(sheet_url)\n",
    "\n",
    "# Try to get the worksheet named \"Face\"\n",
    "try:\n",
    "    sheet = doc.worksheet(\"Face\")\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    raise FileNotFoundError('Worksheet \"Face\" not found.')\n",
    "\n",
    "# Load the data from Google Sheets into a pandas DataFrame\n",
    "data = sheet.get_all_records()\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the Timestamp column to datetime\n",
    "df['Time Stamp'] = pd.to_datetime(df['Time Stamp'])\n",
    "\n",
    "# Plot the number of detections over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "df.set_index('Time Stamp').resample('H').size().plot()\n",
    "plt.title('Number of Detections Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Detections')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the most detected persons\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['Identity'].value_counts().plot(kind='bar')\n",
    "plt.title('Most Detected Persons')\n",
    "plt.xlabel('Person')\n",
    "plt.ylabel('Number of Detections')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the most detected moods\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['Emotion'].value_counts().plot(kind='bar')\n",
    "plt.title('Most Detected Moods')\n",
    "plt.xlabel('Mood')\n",
    "plt.ylabel('Number of Detections')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cda529ae373f75ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c14d5a7215124cc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
